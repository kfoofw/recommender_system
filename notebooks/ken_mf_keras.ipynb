{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorisation with Keras\n",
    "\n",
    "The following is an analysis for performing Matrix Factorisation (MF) with the Keras API using the Embedding layer.\n",
    "\n",
    "For this experiment, we will use a reduced form of the Movie-Lens 20 Million data set. The data set has been processed to extract the top 10000 users and top 2000 movies in terms of ratings counts. \n",
    "\n",
    "Additionally, the user id and movie ids have been preprocessed such that they exist in sequential numerical order. To be more specific, all user ids exist between 0 to 9999, and all movie ids exist between 0 to 1999. The dataset consist of the following columns:\n",
    "- `userId`: User ID ranging from 0 to 9999.\n",
    "- `movieId`: Movie ID ranging from 0 to 1999.\n",
    "- `rating`: Rating that user gave to movie. Range from 0.5 to 5.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Input, Dot, Add, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "df = pd.read_csv(\"../data/small_rating.csv\")\n",
    "\n",
    "N = df.userId.max() + 1 # no of users\n",
    "M = df.movieId.max() + 1 # no of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7307</td>\n",
       "      <td>10</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7307</td>\n",
       "      <td>68</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7307</td>\n",
       "      <td>143</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7307</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7307</td>\n",
       "      <td>85</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0    7307       10     4.5\n",
       "1    7307       68     2.5\n",
       "2    7307      143     3.5\n",
       "3    7307       19     5.0\n",
       "4    7307       85     4.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of users\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of items\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "As with any recommenders system, we will not expect to have a full complete ratings data set (since not all users will rate all movies, and not all movies will receive ratings from all users). Instead, we only have a partially filled matrix which is sparse in nature.\n",
    "\n",
    "Thus, all the available data provided is only in terms of provided ratings, from which we can perform train-test split to obtain a set of training data and testing data. By training on the available ratings, we aim to learn the lower dimensional representations of users and items such that the reconstructed ratings are close to the actual ratings. \n",
    "- Note that each row of training data comes from a pair of User and Item input, with a label of the Rating. \n",
    "- For this analysis, the test dataset will be used for the validation set in the Keras model as shown later.\n",
    "- Note that we can utilise the reduced dimensionality representations of users and items to obtain the ratings that were not given in the sparse ratings matrix (although there will not be any ground truths to compare them with)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSULWEj9qZm6anO_qTV0MSVMNml28H0r0h6VA&usqp=CAU\", width = 500>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducible train test split\n",
    "np.random.seed(1)\n",
    "\n",
    "# Split into train and test\n",
    "df_shuffled = shuffle(df)\n",
    "cutoff = int(0.9 * len(df_shuffled))\n",
    "df_train = df_shuffled.iloc[:cutoff]\n",
    "df_test = df_shuffled.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996526</th>\n",
       "      <td>7460</td>\n",
       "      <td>1153</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864726</th>\n",
       "      <td>2986</td>\n",
       "      <td>1028</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206286</th>\n",
       "      <td>2649</td>\n",
       "      <td>173</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672159</th>\n",
       "      <td>3549</td>\n",
       "      <td>594</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808932</th>\n",
       "      <td>2688</td>\n",
       "      <td>462</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298654</th>\n",
       "      <td>2383</td>\n",
       "      <td>36</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559315</th>\n",
       "      <td>6692</td>\n",
       "      <td>90</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747744</th>\n",
       "      <td>7542</td>\n",
       "      <td>555</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411346</th>\n",
       "      <td>3419</td>\n",
       "      <td>571</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3613875</th>\n",
       "      <td>218</td>\n",
       "      <td>689</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4852822 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating\n",
       "1996526    7460     1153     2.5\n",
       "1864726    2986     1028     4.5\n",
       "4206286    2649      173     3.5\n",
       "4672159    3549      594     1.5\n",
       "3808932    2688      462     3.0\n",
       "...         ...      ...     ...\n",
       "5298654    2383       36     4.0\n",
       "3559315    6692       90     4.0\n",
       "2747744    7542      555     2.0\n",
       "3411346    3419      571     3.0\n",
       "3613875     218      689     4.5\n",
       "\n",
       "[4852822 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>904377</th>\n",
       "      <td>6119</td>\n",
       "      <td>663</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489067</th>\n",
       "      <td>4533</td>\n",
       "      <td>742</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388123</th>\n",
       "      <td>5393</td>\n",
       "      <td>461</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3004970</th>\n",
       "      <td>680</td>\n",
       "      <td>503</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931382</th>\n",
       "      <td>9937</td>\n",
       "      <td>675</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5030793</th>\n",
       "      <td>6374</td>\n",
       "      <td>1366</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>6557</td>\n",
       "      <td>335</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937352</th>\n",
       "      <td>2434</td>\n",
       "      <td>1527</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686059</th>\n",
       "      <td>2747</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322341</th>\n",
       "      <td>2276</td>\n",
       "      <td>423</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating\n",
       "904377     6119      663     1.0\n",
       "2489067    4533      742     3.0\n",
       "4388123    5393      461     3.0\n",
       "3004970     680      503     4.0\n",
       "1931382    9937      675     3.0\n",
       "...         ...      ...     ...\n",
       "5030793    6374     1366     3.0\n",
       "491263     6557      335     3.0\n",
       "3937352    2434     1527     2.5\n",
       "4686059    2747       17     4.0\n",
       "4322341    2276      423     4.0\n",
       "\n",
       "[539203 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Embedding layers\n",
    "Using Keras, we are able to represent Matrix Factorisation (MF) with its Embedding layers. The Embedding layer is commonly used to convert discrete data that might be represented by sparse one-hot encoding into a dense representation with a specified input for hidden dimensionality. \n",
    "\n",
    "For intuition, the Embedding layers are often used in Natural Language Processing (NLP) with text formatting, where words or sequences of words (n-grams) can be used \n",
    "\n",
    "The key inputs for the Embedding layer consists of: \n",
    "- `input_dim`: The number of feature dimensions. In NLP, this refers to the expected vocabulary size for the corpus. In recommenders MF, this represents the number of users or items.\n",
    "- `output_dim`: The hidden/latent dimensionality for dense representation.\n",
    "- `input_length`: This refers to the sequence length that is often used in NLP for n-grams. For recommenders MF, this remains as 1 since the data used does not have sequences.\n",
    "\n",
    "Ignoring the effect of `input_length` since it is 1, what the Embedding layer does is that it constructs a reduced representation of the work as represented by `input_dim` by `output_dim` which is similar to the U or M matrices in MF. Thus, for a given user or item, it is represented by a vector of shape (1 by `hidden_dimension`) in dense representation. Using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"https://lazyprogrammer.me/wp-content/uploads/2016/04/matrix_factorization.png\", width = 500>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this workflow, the output dimensions of the Embedding layer is a 3D tensor of dimensions (batch_size, input_length, output_dim), where:\n",
    "- `batch_size`: Number of training examples used per batch. Specified in the `model.compile()` step.\n",
    "- `input_length`: 1 since we are not dealing with data with sequences (such as n-grams in NLP).\n",
    "- `output_dim`: Hidden/latent dimensions for dense representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer also allows for a regularisation input, which can be specified using other Keras regularizers class objects such as `l2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Keras Embedding layer to represent the following:\n",
    "- U: User matrix of dimensions N x K\n",
    "- V: Item matrix of dimensions K x M\n",
    "- User bias: Matrix of dimensions N x 1. This represents 1 bias per user.\n",
    "- Item bias: Matrix of dimensions M x 1. This represents 1 bias per item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a reference on the Keras Embedding layer, please refer to its [documentation](https://keras.io/api/layers/core_layers/embedding/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model MF Supervised Learning Model\n",
    "For each training data pairing of user and item, we have a training label which represents the rating that the user gave the product. Using Keras, we can set up the `U` and `V` embedding layers (of reduced dimensions) which take in corresponding data inputs in the form of `u` (for user) and `m` (for item). \n",
    "\n",
    "By giving `u` as an input to `U` embedding layer, this extracts out the relevant reduced dimension representation of the particular user in the training data pairing. Likewise, the same goes for the `m` input to the `V` embedding layer.\n",
    "\n",
    "Thereafter, we perform a __dot product__ using the user representation $U_i$ and the item representation $V_i$. In the context of matrix factorisation, this is the exact equivalent of reconstructing the particular rating in the ratings matrix for a given user and item pair.\n",
    "\n",
    "An additional note is that in this case, we will also be accounting for the user and item bias to each rating. We can also represent the bias using Embedding layers as well, but with an `output_dim` of 1. Both the user bias Embedding and item bias Embedding layers will take in corresponding inputs `u` and `m` to obtain the bias associated with each user and item.\n",
    "\n",
    "At the same time, we will also center the data by subtracting the global mean rating of the training data to make the computation more efficient.\n",
    "\n",
    "$$\\hat{rating_{ij}} = U_i \\cdot V_j + user\\_bias_i + item\\_bias_j + rating_{\\mu},\\ where$$\n",
    "$$U_i = User\\ i\\ representation$$\n",
    "$$V_j = Item\\ j\\ representation$$\n",
    "$$user\\_bias_i = Bias\\ for\\ user\\ i$$\n",
    "$$item\\_bias_i = Bias\\ for\\ item\\ j$$\n",
    "$$rating_{\\mu} = Global\\ mean\\ rating\\ (training\\ data)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we obtain the parameters for the experiment such as the hidden/latent dimensionality, the global rating mean for the training data, as well as Keras model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "K = 10 # latent dimensionality\n",
    "\n",
    "# Calculate the mean ratings to be used \n",
    "mu = df_train.rating.mean()\n",
    "\n",
    "# Model parameters\n",
    "epochs = 10\n",
    "reg = 0.001 # regularization penalty if required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we set up the Keras layers as described using the concept of Embedding layers for representation, and obtaining the predicted rating for each pair of user and movie. This is set up such that the model takes in a tuple of 2 inputs `u` and `m`, which are the corresponding user ID and the movie ID.\n",
    "\n",
    "Since we are dealing with ratings (which is a continuous response variable), we can use Mean Squared Error as the loss function.\n",
    "\n",
    "As a slight modification to the mathematical equation, we will make the label data (Y) such that it is the actual ratings minus the global ratings means of the training data. This is demonstrated in the following:\n",
    "$$\\hat{rating_{ij}} - rating_{\\mu} = U_i \\cdot V_j + user\\_bias_i + item\\_bias_j$$\n",
    "$$Y = U_i \\cdot V_j + user\\_bias_i + item\\_bias_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model\n",
    "# Specifying shape of u and m has downstream implications for the \"input_length\" for u_embedding and m_embedding.\n",
    "# Since we are not dealing with text data, the \"input_length\" is 1.\n",
    "u = Input(shape = (1,)) \n",
    "m = Input(shape = (1,))\n",
    "\n",
    "# Output Embedding layer of Keras (1, Sequence_length, K (latent/hidden dimensionality for dense representation))\n",
    "# In the context of matrix factorisation, K is the same for both U and M embedding layers\n",
    "# sequence_length = 1 since we are dealing with discrete users and items, and not NLP text\n",
    "u_embedding = Embedding(input_dim = N, output_dim = K, embeddings_regularizer= l2(reg))(u) # Output Embedding layer (Batch_size, 1, K)\n",
    "m_embedding = Embedding(input_dim = M, output_dim = K, embeddings_regularizer = l2(reg))(m) # Output Embedding layer (Batch_size, 1, K)\n",
    "\n",
    "# Adding Bias for each Embedding layer. \n",
    "u_bias = Embedding(input_dim = N, output_dim = 1, embeddings_regularizer=l2(reg))(u) # (Batch_size, 1, 1)\n",
    "m_bias = Embedding(input_dim = M, output_dim = 1, embeddings_regularizer=l2(reg))(m) # (Batch_size, 1, 1)\n",
    "\n",
    "# x = rating (dot product between user embedding and item embedding)\n",
    "# \"axes\" input is to specify the axis for performing the dot product operation\n",
    "ratings = Dot(axes=2)([u_embedding, m_embedding]) # (Batch_size, 1, 1)\n",
    "\n",
    "# Account for biases in eventual rating\n",
    "ratings = Add()([ratings, u_bias, m_bias])\n",
    "\n",
    "# Flattening/Reducing from 3D tensor to 2D tensor\n",
    "ratings = Flatten()(ratings) # (Batch_size, 1)\n",
    "\n",
    "model = Model(inputs=[u, m], outputs = ratings)\n",
    "model.compile(\n",
    "    # Mse loss function includes regularisation\n",
    "    loss = \"mse\", \n",
    "    # Optimizer with hyper-parameters\n",
    "    optimizer = SGD(lr = 0.01, momentum = 0.9),\n",
    "    # Explicit stating of mse in metrics is returns loss function without regularisation portion\n",
    "    metrics = [\"mse\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 10)        100000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 10)        20000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 1)         0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 1)         10000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 1)         2000        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1, 1)         0           dot[0][0]                        \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1)            0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 132,000\n",
      "Trainable params: 132,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model summary, we can observe how the inputs `u` and `m` are used to connect with the various embedding layers (`u` for `U` & `u_bias`, `m` for `M` & `m_bias`). Thereafter, we obtain the predicted ratings by performing the necessary dot product with arithmetic operations (accounting for the bias).\n",
    "\n",
    "As shown in the following, the inputs are based on the pairings of the user ID and movie ID for each rating. The test dataset which we previously obtained is used for the validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37913/37913 [==============================] - 73s 2ms/step - loss: 0.9935 - mse: 0.9330 - val_loss: 0.9435 - val_mse: 0.8905\n",
      "Epoch 2/10\n",
      "37913/37913 [==============================] - 73s 2ms/step - loss: 0.9414 - mse: 0.8851 - val_loss: 0.9375 - val_mse: 0.8790\n",
      "Epoch 3/10\n",
      "37913/37913 [==============================] - 74s 2ms/step - loss: 0.9396 - mse: 0.8802 - val_loss: 0.9373 - val_mse: 0.8776\n",
      "Epoch 4/10\n",
      "37913/37913 [==============================] - 91s 2ms/step - loss: 0.9395 - mse: 0.8796 - val_loss: 0.9373 - val_mse: 0.8773\n",
      "Epoch 5/10\n",
      "37913/37913 [==============================] - 81s 2ms/step - loss: 0.9395 - mse: 0.8795 - val_loss: 0.9372 - val_mse: 0.8773\n",
      "Epoch 6/10\n",
      "37913/37913 [==============================] - 77s 2ms/step - loss: 0.9395 - mse: 0.8795 - val_loss: 0.9372 - val_mse: 0.8772\n",
      "Epoch 7/10\n",
      "37913/37913 [==============================] - 85s 2ms/step - loss: 0.9395 - mse: 0.8794 - val_loss: 0.9373 - val_mse: 0.8773\n",
      "Epoch 8/10\n",
      "37913/37913 [==============================] - 78s 2ms/step - loss: 0.9395 - mse: 0.8795 - val_loss: 0.9372 - val_mse: 0.8773\n",
      "Epoch 9/10\n",
      "37913/37913 [==============================] - 89s 2ms/step - loss: 0.9395 - mse: 0.8795 - val_loss: 0.9373 - val_mse: 0.8773\n",
      "Epoch 10/10\n",
      "18411/37913 [=============>................] - ETA: 48s - loss: 0.9391 - mse: 0.8791"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ef4e50a95c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     validation_data = (\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "matrix_factorisation = model.fit(\n",
    "    # Training data in tuples (u, m)\n",
    "    x = [df_train.userId.values, df_train.movieId.values],\n",
    "    \n",
    "    # Labels are the deviations from the average ratings\n",
    "    y = df_train.rating.values - mu,\n",
    "    epochs= epochs,\n",
    "    batch_size = 128,\n",
    "    validation_data = (\n",
    "        [df_test.userId.values, df_test.movieId.values],\n",
    "        df_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses (loss is MSE with regularisation term)\n",
    "plt.plot(matrix_factorisation.history['loss'], label=\"train loss\")\n",
    "plt.plot(matrix_factorisation.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metric (\"mse\" metric is MSE without regularisation term)\n",
    "plt.plot(matrix_factorisation.history['mse'], label=\"train mse\")\n",
    "plt.plot(matrix_factorisation.history['val_mse'], label=\"test mse\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
